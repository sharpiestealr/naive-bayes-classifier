{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nome: Ariel Tamezgui Leventhal (arieltl@al.insper.edu.br)\n",
    "* Nome: Felipe Liberman Fuchs (felipelf2@al.insper.edu.br)\n",
    "* Nome: Victoria Leal Garcia de Souza (victorialgs@al.insper.edu.br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from emoji import UNICODE_EMOJI\n",
    "import re\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Rocketz\\Desktop\\naive-bayes-classifier\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ps5.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@jamiltdavis @vicious696 i say the cutoff shou...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@rgt_85 @obe1plays when @rgt_85 tweets at you....</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@one_gamergal6 @xboxstockalerts if you guys st...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mbeasleysburner @wario64 they are literally l...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first couple followers to give us a private  m...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Categoria Unnamed: 2\n",
       "0  @jamiltdavis @vicious696 i say the cutoff shou...          4        NaN\n",
       "1  @rgt_85 @obe1plays when @rgt_85 tweets at you....          4        NaN\n",
       "2  @one_gamergal6 @xboxstockalerts if you guys st...          3        NaN\n",
       "3  @mbeasleysburner @wario64 they are literally l...          4        NaN\n",
       "4  first couple followers to give us a private  m...          4        NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>gabas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@cataferal hi tom, a couple things. in your f1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@infamizmikep if the conversation is about gam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@jte2409 @mcquack306 no free upgrade from ps4 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@abduplays_ just in time because i just got a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y‚Äôall gotta ps5?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Categoria  gabas\n",
       "0  @cataferal hi tom, a couple things. in your f1...        NaN      1\n",
       "1  @infamizmikep if the conversation is about gam...        NaN      2\n",
       "2  @jte2409 @mcquack306 no free upgrade from ps4 ...        NaN      2\n",
       "3  @abduplays_ just in time because i just got a ...        NaN      4\n",
       "4                                   y‚Äôall gotta ps5?        NaN      4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O produto escolhido foi o console Playstation 5 (PS5). Para fins de relev√¢ncia, optamos seguir a seguinte lista: \n",
    "\n",
    "* Muito relevante: Tweets que possuem uma cr√≠tica (positiva ou negativa) sobre o produto que tenha fundamento em  alguma qualidade ou caracter√≠stica do console.\n",
    "* Relevante: Tweets que possuem uma cr√≠tica (positiva ou negativa) sobre o produto sem especificar alguma qualidade ou caracter√≠stica do console.\n",
    "* Pouco Relevante: Tweets que comentam sobre a falta de estoque do PS5 e/ou da dificuldade de comprar um console.\n",
    "* Irrelevante: Tweets que n√£o se encaixam em nenhuma das outras categorias, incluindo: memes, reclama√ß√µes sobre algum jogo de PS5, promo√ß√µes e sorteios para conseguir um PS5, entre outros.\n",
    "\n",
    "Tweets que poderiam ser classificados como Relevante mas que contenham alguma proposta de solu√ß√£o a algum problema indicado nos Tweets foram classificados como Muito Relevante, mesmo n√£o tendo coment√°rio espec√≠fico sobre alguma qualidade ou caracter√≠stica do console. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P(Categoria|Texto) = \\frac{P(Texto|Categoria) \\cdot P(Categoria)}{P(Text)} = \\frac{\\sum_0^n P(Palavra|Categoria) \\cdot P(Categoria)}{P(Text)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Categoria = train.Categoria.astype('category')\n",
    "train.Categoria.cat.categories = [\"Muito Relevante\",\"Relevante\", \"Pouco Relevante\", \"Irrelevante\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira fase da cria√ß√£o do classificador foi identificar termos que poderiam prejudicar o classificador. Foram feitas listas de caracteres especiais e stopwords para serem filtrados do corpo principal do dataset, e al√©m disso tamb√©m foram removidos links (URLs) e nomes de usu√°rios nos tweets. Emojis foram separados caso estivessem presentes em tweets como \"üòÇüòÇüòÇ\" para melhor identificar a presen√ßa e utiliza√ß√£o destes.\n",
    "\n",
    "Nas c√©lulas abaixo est√£o as listas de stopwords e caracteres especiais, e as fun√ß√µes que foram usadas para identificar os itens mencionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_letters = {\",\", \"'\", '\"', \".\", \"!\", \"?\", \";\", \":\", \"[\", \"]\",\"{\", \"}\", \"(\", \")\",\n",
    "                   \"#\", \"/\",  \"\\\\\", \"https\",\"+\", \"*\", \"-\"}\n",
    "stopwords = {'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as',\n",
    "             'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot',\n",
    "             'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', \n",
    "             'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\",\n",
    "             \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i',\n",
    "             \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me',\n",
    "             'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', \n",
    "             'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \n",
    "             \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their',\n",
    "             'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\",\n",
    "             \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we',\n",
    "             \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\",\n",
    "             'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you',\n",
    "             \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_user(word): # retorna se uma palavra √© um nome de usuario \n",
    "    return (not word[0] == \"@\") if len(word) > 0 else True\n",
    "\n",
    "def is_not_stopword(word): # retorna se uma palavra √© uma stopword\n",
    "    return not word in stopwords\n",
    "\n",
    "def is_emoji(letter): # retorna se um caractere √© um emoji\n",
    "    return letter in UNICODE_EMOJI[\"en\"]\n",
    "\n",
    "def is_special(letter): # retorna se o caractere √© um caractere especial\n",
    "    return letter in special_letters\n",
    "\n",
    "def is_url(sentence):    \n",
    "    pattern = re.compile(\"/(((http|ftp|https):\\/{2})+(([0-9a-z_-]+\\.)+(aero|asia|biz|cat|com|coop|edu|gov|info|int|jobs|mil|mobi|museum|name|net|org|pro|tel|travel|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cu|cv|cx|cy|cz|cz|de|dj|dk|dm|do|dz|ec|ee|eg|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mn|mn|mo|mp|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|nom|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ra|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|sj|sk|sl|sm|sn|so|sr|st|su|sv|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw|arpa)(:[0-9]+)?((\\/([~0-9a-zA-Z\\#\\+\\%@\\.\\/_-]+))?(\\?[0-9a-zA-Z\\+\\%@\\/&\\[\\];=_-]+)?)?))\\b/imuS\")\n",
    "    return not (pattern.match(sentence) is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as fun√ß√µes para limpar o dataset, foi criada uma fun√ß√£o (clean_up) que as implementassem. O filtro n√£o foi feito removendo os itens filtrados do dataset, mas n√£o os adicionando √† lista de palavras em qualquer uma das categorias (Muito Relevante, Relevante, Pouco Relevante, Irrelevante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(text):\n",
    "    split_text = text.split()\n",
    "    \n",
    "    for sentence in range(len(split_text)):\n",
    "        if is_url(split_text[sentence]):\n",
    "            split_text[sentence] = \" \" # remove URLs\n",
    "            \n",
    "    final_text= \"\"\n",
    "    \n",
    "    for letter in \" \".join(split_text):\n",
    "        if is_emoji(letter):\n",
    "            final_text += f\" {letter} \" # separa emojis\n",
    "        elif is_special(letter):\n",
    "            final_text += \" \" # filtra caracteres especiais com exce√ß√£o de \"_\" para evitar atrapalhar\n",
    "                              # o filtro de nome de usuarios\n",
    "        else:\n",
    "            final_text += letter \n",
    "    \n",
    "    return ' '.join(word.replace(\"_\",\" \")\n",
    "                    for word in final_text.split() if \n",
    "                    is_not_user(word) and\n",
    "                    is_not_stopword(word)).strip() # filtra usu√°rios, stopwords, caracteres especiais e \"_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, um exemplo de alguns dos tweets da base de dados de treinamento e a categoria que foi manualmente dada a eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@jamiltdavis @vicious696 i say the cutoff shou...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@rgt_85 @obe1plays when @rgt_85 tweets at you....</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@one_gamergal6 @xboxstockalerts if you guys st...</td>\n",
       "      <td>Pouco Relevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mbeasleysburner @wario64 they are literally l...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first couple followers to give us a private  m...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento        Categoria  \\\n",
       "0  @jamiltdavis @vicious696 i say the cutoff shou...      Irrelevante   \n",
       "1  @rgt_85 @obe1plays when @rgt_85 tweets at you....      Irrelevante   \n",
       "2  @one_gamergal6 @xboxstockalerts if you guys st...  Pouco Relevante   \n",
       "3  @mbeasleysburner @wario64 they are literally l...      Irrelevante   \n",
       "4  first couple followers to give us a private  m...      Irrelevante   \n",
       "\n",
       "  Unnamed: 2  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = {cat: dict() for cat in train.Categoria.cat.categories}\n",
    "words = set()\n",
    "\n",
    "for i, tweet_data in train.iterrows(): # itera pelas linhas do dataframe\n",
    "    tweet = tweet_data.Treinamento # separa a coluna do tweet\n",
    "    \n",
    "    for word in clean_up(tweet).split(): # faz limpezas no texto\n",
    "        words.add(word)\n",
    "        cat_dict = words_count[tweet_data.Categoria]\n",
    "        cat_dict[word] = cat_dict.get(word, 0)+1 # garante que a palavra existe no dicionario.\n",
    "                                                 # caso exista o count √© incrementado,\n",
    "                                                 # caso contr√°rio a palavra √© adicionada com count=1.\n",
    "        \n",
    "M = words_count['Muito Relevante']\n",
    "R = words_count['Relevante']\n",
    "P = words_count['Pouco Relevante']\n",
    "I = words_count['Irrelevante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(words)         # total de palavras no banco de dados\n",
    "totalM = (sum(M.values())) # total de palavras na categoria Muito Relevante\n",
    "totalR = (sum(R.values())) # total de palavras na categoria Relevante\n",
    "totalP = (sum(P.values())) # total de palavras na categoria Pouco Relevante\n",
    "totalI = (sum(I.values())) # total de palavras na categoria Irrelevante\n",
    "p_cats = train.Categoria.value_counts()/len(train) #probabilidade de um tweet ser cada categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar o classificador, foram separadas as palavras em cada categoria, para verificar qual a frequ√™ncia de uso delas. Com essa lista de frequ√™ncia, cada palavra teve atribuida a ela um valor de relev√¢ncia, e assim foi comparada √† base de dados de teste para concluir se os tweets analizados eram ou n√£o relevantes com base na frequ√™ncia de certas palavras em cada lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [] # lista de classifica√ß√µes, mesma ordem de test\n",
    "\n",
    "for i, tweet_data in test.iterrows():  # itera pelas linhas do dataframe\n",
    "    # valores inicias para a probabilidade do tweet ser determinada relevancia, come√ßa em probabilidade da categoria para\n",
    "    # sera multiplicado pela probabilidade de cada palavra ser cada categoria.\n",
    "    i = p_cats[\"Irrelevante\"]\n",
    "    p = p_cats[\"Pouco Relevante\"]\n",
    "    r = p_cats[\"Relevante\"]\n",
    "    m = p_cats[\"Muito Relevante\"]\n",
    "    tweet = tweet_data.Teste # separa a coluna do tweet\n",
    "    \n",
    "    # faz limpezas no texto\n",
    "    for word in clean_up(tweet).split(): \n",
    "        \n",
    "        # calcula as probabilidades de cada relevancia fazendo suavizavao de laplace\n",
    "        r *= (R.get(word, 0) + 1) / (totalR + total) \n",
    "        p *= (P.get(word, 0) + 1) / (totalP + total) \n",
    "        i *= (I.get(word, 0) + 1) / (totalI + total) \n",
    "        m *= (M.get(word, 0) + 1) / (totalM + total)\n",
    "        \n",
    "    result = {\"Muito Relevante\": m,\"Relevante\": r,\"Pouco Relevante\": p,\"Irrelevante\": i}\n",
    "    # dicion√°rio para comparar dentro do MAX abaixo\n",
    "    \n",
    "    l.append(max(result, key = result.get)) # compara os valores de r, p, i, e adiciona √† lista L \n",
    "\n",
    "test.Categoria = pd.Categorical(values=l,categories=[\"Muito Relevante\",\"Relevante\", \n",
    "                                                     \"Pouco Relevante\", \"Irrelevante\"],ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.gabas = test.gabas.astype(\"category\")\n",
    "test.gabas.cat.categories = test.Categoria.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Acerto\"] = [(\"Acertou\" if (row.gabas==row.Categoria)  else \"Errou\") for i,row in test.iterrows()]\n",
    "test.Acerto = test.Acerto.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, o √≠ndice de acertos e erros do classificador com base em um gabarito manualmente gerado.\n",
    "\n",
    "Tamb√©m foram feitas tabelas que mostram as frequ√™ncias absolutas e relativas que indicam os acertos em rela√ß√£o ao gabarito, para que fosse poss√≠vel ver onde houvesse maior dificuldade de discernimento do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acerto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acertou</th>\n",
       "      <td>65.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Errou</th>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Acerto\n",
       "Acertou    65.6\n",
       "Errou      34.4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test.Acerto.value_counts(normalize=True)*100).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gabas</th>\n",
       "      <th>Muito Relevante</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Pouco Relevante</th>\n",
       "      <th>Irrelevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Muito Relevante</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pouco Relevante</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gabas            Muito Relevante  Relevante  Pouco Relevante  Irrelevante\n",
       "Categoria                                                                \n",
       "Muito Relevante                3          0                0            8\n",
       "Relevante                      8         19                3           36\n",
       "Pouco Relevante                0          0               27            5\n",
       "Irrelevante                    3         17                6          115"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Categoria,test.gabas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gabas</th>\n",
       "      <th>Muito Relevante</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Pouco Relevante</th>\n",
       "      <th>Irrelevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Muito Relevante</th>\n",
       "      <td>27.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>12.12</td>\n",
       "      <td>28.79</td>\n",
       "      <td>4.55</td>\n",
       "      <td>54.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pouco Relevante</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.38</td>\n",
       "      <td>15.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>2.13</td>\n",
       "      <td>12.06</td>\n",
       "      <td>4.26</td>\n",
       "      <td>81.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gabas            Muito Relevante  Relevante  Pouco Relevante  Irrelevante\n",
       "Categoria                                                                \n",
       "Muito Relevante            27.27       0.00             0.00        72.73\n",
       "Relevante                  12.12      28.79             4.55        54.55\n",
       "Pouco Relevante             0.00       0.00            84.38        15.62\n",
       "Irrelevante                 2.13      12.06             4.26        81.56"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Categoria,test.gabas,normalize=\"index\").round(4)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras da categoria Muito Relevante : 592\n",
      "Quantidade de palavras da categoria Relevante : 1870\n",
      "Quantidade de palavras da categoria Pouco Relevante : 1827\n",
      "Quantidade de palavras da categoria Irrelevante : 5328\n"
     ]
    }
   ],
   "source": [
    "pal = [totalM, totalR, totalP, totalI]\n",
    "cats = [\"Muito Relevante\", \"Relevante\", \"Pouco Relevante\", \"Irrelevante\"]\n",
    "\n",
    "for i in range (0, len(pal)):\n",
    "    print(\"Quantidade de palavras da categoria\", cats[i], \":\", pal[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, as frequ√™ncias de cada categoria de relev√¢ncia em cada um dos datasets. Primeiro, a base de treinamento, e depois a de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irrelevante        312\n",
       "Relevante           88\n",
       "Pouco Relevante     74\n",
       "Muito Relevante     26\n",
       "Name: Categoria, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Categoria.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irrelevante        164\n",
       "Pouco Relevante     36\n",
       "Relevante           36\n",
       "Muito Relevante     14\n",
       "Name: gabas, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.gabas.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conclus√£o\n",
    "\n",
    "O Classificador Naive-Bayes criado com o dataset de treinamento obteve um acerto de 65.6%. √â poss√≠vel concluir que o classificador teve resultados razo√°veis e na m√©dia do esperado para um classificador simples. Ele √© considerado simples por n√£o levar em conta coisas como duplas-nega√ß√µes, sarcasmo, e outras nuances lingu√≠sticas.\n",
    "\n",
    "A fim de economizar tempo da equipe de marketing do cliente, pode-se afirmar que o classificador cumpriu parcialmente com seus objetivos, porque mesmo tendo dificuldade em discernir entre as categorias muito relevante e relevante, ele tem uma boa precis√£o quanto aos tweets irrelevantes e pouco relevantes. Sem estes, a maioria restante s√£o de tweets com algum grau de relev√¢ncia, e estes s√£o fundamentais para a interven√ß√£o da √°rea de marketing.\n",
    "\n",
    "O classificador ainda n√£o est√° em um ponto no qual se possa excluir totalmente a an√°lise manual dos tweets uma vez que 34.4% dos tweets ainda s√£o classificados incorretamente, que s√£o em sua maioria tweets muito relevantes ou relevantes. Isto pode ter sido causado por diferen√ßas de interpreta√ß√£o na classifica√ß√£o manual dos tweets, mas tamb√©m √© afetado pelo n√£o-reconhecimento de coisas como o sarcasmo que j√° foram citadas. Como plano de melhoria e motivo para continua√ß√£o do investimento no projeto, seria interessante expandir o dataset em an√°lise com a classifica√ß√£o manual feita por pessoas da √°rea de marketing, melhorando a confiabilidade nos dados do dataset de treinamento. Outra solu√ß√£o que possa ser mais fact√≠vel de realizar a curto prazo seria procurar adicionar √† base de treinamento tweets para melhor treinar o classificador, de maneira que haja uma propor√ß√£o mais igual entre a quantidade de tweets de cada categoria. Outra poss√≠vel melhoria seria implementar detec√ß√£o de ironia, para isso poder√≠amos usar esta [pesquisa](https://aclanthology.org/S18-1005/) como refer√™ncia.\n",
    "\n",
    "Seria interessante usar um classificador de Naive-Bayes mais avan√ßado para identificar o interesse de algu√©m em comportamentos ou atitudes preocupantes, como forma de seguran√ßa p√∫blica. Por exemplo, [essa reportagem](https://www.nytimes.com/2018/09/06/us/social-media-monitoring-school-shootings.html) indica que seria poss√≠vel identificar amea√ßas p√∫blicas por meio do monitoramento das redes sociais. Por mais que isso seja invasivo e pouco custo-efetivo, √© uma aplica√ß√£o poss√≠vel do classificador. \n",
    "\n",
    "Ao mesmo tempo, outra aplica√ß√£o seria para medir a opini√£o popular a respeito de uma comunidade ou um termo que a diz respeito, parecido com como se faz no Facebook. Digitar algumas palavras espec√≠ficas em um coment√°rio (especialmente relacionadas a etnia, sexualidade, g√™nero e nacionalidade) pode te causar uma penalidade como uma proibi√ß√£o de interagir com e criar novos posts por um per√≠odo de tempo, porque o algoritmo do Facebook identificou que s√£o palavras geralmente usadas ofensivamente, e por isso passa a punir as pessoas que as usam. Este √© um exemplo de algoritmo que, assim como o desenvolvido neste projeto, n√£o √© capaz de reconhecer sarcasmo e humor, e acaba punindo pessoas que n√£o ofenderam ningu√©m com uma palavra que, por um motivo, foi parar na lista de termos ofensivos. Isto revela uma inseguran√ßa grande sobre a classifica√ß√£o: √© poss√≠vel gerar uma falsa perspectiva sobre o objeto estudado com base no dataset obtido.\n",
    "\n",
    "Sobre a necessidade de investimento adicional no dataset de treinamento, n√£o √© poss√≠vel criar um novo dataset automaticamente atrav√©s do pr√≥prio classificador j√° existente pois isso propagaria os erros feitos pelo classificador, reduzindo sua exatid√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(filename)\n",
    "df2 = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "df1 = df1.drop(\"Unnamed: 2\",axis=1)\n",
    "df2 = df2.drop(\"Categoria\",axis=1)\n",
    "df1 = df1.rename(columns={\"Treinamento\":\"Tweet\"})\n",
    "df2 = df2.rename(columns={\"Teste\":\"Tweet\",\"gabas\":\"Categoria\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Muito Relevante', 'Relevante', 'Pouco Relevante', 'Irrelevante'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.concat([df1,df2],ignore_index=True)\n",
    "tweets.Tweet = tweets.Tweet.apply(clean_up)\n",
    "tweets.Categoria = tweets.Categoria.astype('category')\n",
    "tweets.Categoria.cat.categories = [\"Muito Relevante\",\"Relevante\", \"Pouco Relevante\", \"Irrelevante\"]\n",
    "\n",
    "tweets.Categoria.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(df):\n",
    "    words_count = {cat: dict() for cat in df.Categoria.cat.categories}\n",
    "    words = set()\n",
    "    for i, tweet_data in df.iterrows(): # itera pelas linhas do dataframe\n",
    "        tweet = tweet_data.Tweet # separa a coluna do tweet\n",
    "\n",
    "        for word in tweet.split(): # faz limpezas no texto\n",
    "            words.add(word)\n",
    "            cat_dict = words_count[tweet_data.Categoria]\n",
    "            cat_dict[word] = cat_dict.get(word, 0)+1 # garante que a palavra existe no dicionario. caso exista o count √© incrementado, caso contr√°rio a palavra √© adicionada com count=1\n",
    "    return words, words_count, df.Categoria.value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(words,words_count,p_cats,df):\n",
    "\n",
    "    M = words_count['Muito Relevante']\n",
    "    R = words_count['Relevante']\n",
    "    P = words_count['Pouco Relevante']\n",
    "    I = words_count['Irrelevante']\n",
    "\n",
    "    total = len(words)         # total de palavras no banco de dados\n",
    "    totalM = (sum(M.values())) # total de palavras na categoria Muito Relevante\n",
    "    totalR = (sum(R.values())) # total de palavras na categoria Relevante\n",
    "    totalP = (sum(P.values())) # total de palavras na categoria Pouco Relevante\n",
    "    totalI = (sum(I.values())) # total de palavras na categoria Irrelevante\n",
    "\n",
    "    l = [] # lista de classifica√ß√µes, mesma ordem de test\n",
    "    \n",
    "    for i, tweet_data in df.iterrows():  # itera pelas linhas do dataframe\n",
    "        # valores inicias para a probabilidade do tweet ser determinada relevancia, come√ßa em probabilidade da categoria para\n",
    "        # sera multiplicado pela probabilidade de cada palavra ser cada categoria.\n",
    "        i = p_cats[\"Irrelevante\"]\n",
    "        p = p_cats[\"Pouco Relevante\"]\n",
    "        r = p_cats[\"Relevante\"]\n",
    "        m = p_cats[\"Muito Relevante\"]\n",
    "        tweet = tweet_data.Tweet # separa a coluna do tweets\n",
    "\n",
    "        # faz limpezas no texto\n",
    "        for word in tweet.split(): \n",
    "\n",
    "            # calcula as probabilidades de cada relevancia fazendo suavizavao de laplace\n",
    "            r *= (R.get(word, 0) + 1) / (totalR + total) \n",
    "            p *= (P.get(word, 0) + 1) / (totalP + total) \n",
    "            i *= (I.get(word, 0) + 1) / (totalI + total) \n",
    "            m *= (M.get(word, 0) + 1) / (totalM + total)\n",
    "\n",
    "        result = {\"Muito Relevante\": m,\"Relevante\": r,\"Pouco Relevante\": p,\"Irrelevante\": i} # dicion√°rio para comparar dentro do MAX abaixo\n",
    "\n",
    "        l.append(max(result, key = result.get)) # compara os valores de r, p, i, e adiciona √† lista L \n",
    "\n",
    "    df[\"Classifica√ß√£o\"] = pd.Categorical(values=l,categories=[\"Muito Relevante\",\"Relevante\", \"Pouco Relevante\", \"Irrelevante\"],ordered=True)\n",
    "  \n",
    "    df[\"Acerto\"] = [\"Acertou\" if (row[\"Classifica√ß√£o\"]==row.Categoria) else \"Errou\" for i,row in df.iterrows()]\n",
    "    \n",
    "    df.Acerto = df.Acerto.astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sample() got an unexpected keyword argument 'ignore_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c32154f7d99a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mrandom_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseeds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Separa o df em train e test, com teste de 1/3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sample() got an unexpected keyword argument 'ignore_index'"
     ]
    }
   ],
   "source": [
    "lista_acertos = list()\n",
    "acertos_max = 0\n",
    "seeds = [(11*i+669+i**2) for i in range(100)] # para manter consist√™ncia entre execu√ß√µes\n",
    "\n",
    "for i in range(100):\n",
    "    random_tweets = tweets.sample(frac=1, random_state=seeds[i], ignore_index=True)\n",
    "    # Separa o df em train e test, com teste de 1/3\n",
    "    \n",
    "    train2, test2 =(random_tweets.iloc[:500], random_tweets.iloc[500:])\n",
    "    result = test_classifier(*train_classifier(train2), test2.copy())\n",
    "    lista_acertos.append(result.Acerto.value_counts(normalize=True).Acertou*100)\n",
    "    acertos_max = max(acertos_max,lista_acertos[-1])\n",
    "    if acertos_max == lista_acertos[-1]:\n",
    "        max_acertos_test = result\n",
    "\n",
    "tabela_acertos = pd.DataFrame({\"Acertos\":lista_acertos})\n",
    "tabela_acertos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Histograma de Acertos em diferentes divis√µes de Teste e Treinamento\")\n",
    "plt.xlabel(\"Acertos (%)\")\n",
    "tabela_acertos.Acertos.hist(bins=15,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(max_acertos_test[\"Classifica√ß√£o\"],max_acertos_test.Categoria,normalize=\"index\").round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(tabela_acertos, vert = False, meanline = True, showcaps = True, showbox = True, showfliers = True,\n",
    "            showmeans = True, notch = True, manage_ticks = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## checklist itens extra\n",
    "\n",
    "- [x] Espa√ßamento entre emojis\n",
    "- [x] 4 categorias (obrigatorio)\n",
    "- [x] Explicar porque n√£o pode usar o classificador para gerar mais dados de treinamento\n",
    "- [x] Fazer o item 6\n",
    "- [x] Propor outro cenario para naive-bayes\n",
    "- [x] Sugerir melhoria com pesquisa\n",
    "#### Limpezas e transformacoes:\n",
    "    - [x] Stopwords\n",
    "    - [x] Nomes de usuario\n",
    "    - [x] Limpeza de urls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)\n",
    "\n",
    "----\n",
    "## Referencias:\n",
    "* https://mathiasbynens.be/demo/url-regex\n",
    "* https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.htmlhttps://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
