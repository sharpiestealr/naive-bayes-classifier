{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nome: Ariel Tamezgui Leventhal (arieltl@al.insper.edu.br)\n",
    "* Nome: Felipe Liberman Fuchs (felipelf2@al.insper.edu.br)\n",
    "* Nome: Victoria Leal Garcia de Souza (victorialgs@al.insper.edu.br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from emoji import UNICODE_EMOJI\n",
    "import re\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Rocketz\\Desktop\\naive-bayes-classifier\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ps5.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@jamiltdavis @vicious696 i say the cutoff shou...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@rgt_85 @obe1plays when @rgt_85 tweets at you....</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@one_gamergal6 @xboxstockalerts if you guys st...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mbeasleysburner @wario64 they are literally l...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first couple followers to give us a private  m...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Categoria Unnamed: 2\n",
       "0  @jamiltdavis @vicious696 i say the cutoff shou...          4        NaN\n",
       "1  @rgt_85 @obe1plays when @rgt_85 tweets at you....          4        NaN\n",
       "2  @one_gamergal6 @xboxstockalerts if you guys st...          3        NaN\n",
       "3  @mbeasleysburner @wario64 they are literally l...          4        NaN\n",
       "4  first couple followers to give us a private  m...          4        NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>gabas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@cataferal hi tom, a couple things. in your f1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@infamizmikep if the conversation is about gam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@jte2409 @mcquack306 no free upgrade from ps4 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@abduplays_ just in time because i just got a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y’all gotta ps5?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Categoria  gabas\n",
       "0  @cataferal hi tom, a couple things. in your f1...        NaN      1\n",
       "1  @infamizmikep if the conversation is about gam...        NaN      2\n",
       "2  @jte2409 @mcquack306 no free upgrade from ps4 ...        NaN      2\n",
       "3  @abduplays_ just in time because i just got a ...        NaN      4\n",
       "4                                   y’all gotta ps5?        NaN      4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O produto escolhido foi o console Playstation 5 (PS5). Para fins de relevância, optamos seguir a seguinte lista: \n",
    "\n",
    "* Muito relevante: Tweets que possuem uma crítica (positiva ou negativa) sobre o produto que tenha fundamento em  alguma qualidade ou característica do console.\n",
    "* Relevante: Tweets que possuem uma crítica (positiva ou negativa) sobre o produto sem especificar alguma qualidade ou característica do console.\n",
    "* Pouco Relevante: Tweets que comentam sobre a falta de estoque do PS5 e/ou da dificuldade de comprar um console.\n",
    "* Irrelevante: Tweets que não se encaixam em nenhuma das outras categorias, incluindo: memes, reclamações sobre algum jogo de PS5, promoções e sorteios para conseguir um PS5, entre outros.\n",
    "\n",
    "Tweets que poderiam ser classificados como Relevante mas que contenham alguma proposta de solução a algum problema indicado nos Tweets foram classificados como Muito Relevante, mesmo não tendo comentário específico sobre alguma qualidade ou característica do console. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P(Categoria|Texto) = \\frac{P(Texto|Categoria) \\cdot P(Categoria)}{P(Text)} = \\frac{\\sum_0^n P(Palavra|Categoria) \\cdot P(Categoria)}{P(Text)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Categoria = train.Categoria.astype('category')\n",
    "train.Categoria.cat.categories = [\"Muito Relevante\",\"Relevante\", \"Pouco Relevante\", \"Irrelevante\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira fase da criação do classificador foi identificar termos que poderiam prejudicar o classificador. Foram feitas listas de caracteres especiais e stopwords para serem filtrados do corpo principal do dataset, e além disso também foram removidos links (URLs) e nomes de usuários nos tweets. Emojis foram separados caso estivessem presentes em tweets como \"😂😂😂\" para melhor identificar a presença e utilização destes.\n",
    "\n",
    "Nas células abaixo estão as listas de stopwords e caracteres especiais, e as funções que foram usadas para identificar os itens mencionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_letters = {\",\", \"'\", '\"', \".\", \"!\", \"?\", \";\", \":\", \"[\", \"]\",\"{\", \"}\", \"(\", \")\",\n",
    "                   \"#\", \"/\",  \"\\\\\", \"https\",\"+\", \"*\", \"-\"}\n",
    "stopwords = {'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as',\n",
    "             'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot',\n",
    "             'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', \n",
    "             'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\",\n",
    "             \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i',\n",
    "             \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me',\n",
    "             'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', \n",
    "             'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \n",
    "             \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their',\n",
    "             'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\",\n",
    "             \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we',\n",
    "             \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\",\n",
    "             'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you',\n",
    "             \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_user(word): # retorna se uma palavra é um nome de usuario \n",
    "    return (not word[0] == \"@\") if len(word) > 0 else True\n",
    "\n",
    "def is_not_stopword(word): # retorna se uma palavra é uma stopword\n",
    "    return not word in stopwords\n",
    "\n",
    "def is_emoji(letter): # retorna se um caractere é um emoji\n",
    "    return letter in UNICODE_EMOJI[\"en\"]\n",
    "\n",
    "def is_special(letter): # retorna se o caractere é um caractere especial\n",
    "    return letter in special_letters\n",
    "\n",
    "def is_url(sentence):    \n",
    "    pattern = re.compile(\"/(((http|ftp|https):\\/{2})+(([0-9a-z_-]+\\.)+(aero|asia|biz|cat|com|coop|edu|gov|info|int|jobs|mil|mobi|museum|name|net|org|pro|tel|travel|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cu|cv|cx|cy|cz|cz|de|dj|dk|dm|do|dz|ec|ee|eg|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mn|mn|mo|mp|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|nom|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ra|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|sj|sk|sl|sm|sn|so|sr|st|su|sv|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw|arpa)(:[0-9]+)?((\\/([~0-9a-zA-Z\\#\\+\\%@\\.\\/_-]+))?(\\?[0-9a-zA-Z\\+\\%@\\/&\\[\\];=_-]+)?)?))\\b/imuS\")\n",
    "    return not (pattern.match(sentence) is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as funções para limpar o dataset, foi criada uma função (clean_up) que as implementassem. O filtro não foi feito removendo os itens filtrados do dataset, mas não os adicionando à lista de palavras em qualquer uma das categorias (Muito Relevante, Relevante, Pouco Relevante, Irrelevante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(text):\n",
    "    split_text = text.split()\n",
    "    \n",
    "    for sentence in range(len(split_text)):\n",
    "        if is_url(split_text[sentence]):\n",
    "            split_text[sentence] = \" \" # remove URLs\n",
    "            \n",
    "    final_text= \"\"\n",
    "    \n",
    "    for letter in \" \".join(split_text):\n",
    "        if is_emoji(letter):\n",
    "            final_text += f\" {letter} \" # separa emojis\n",
    "        elif is_special(letter):\n",
    "            final_text += \" \" # filtra caracteres especiais com exceção de \"_\" para evitar atrapalhar\n",
    "                              # o filtro de nome de usuarios\n",
    "        else:\n",
    "            final_text += letter \n",
    "    \n",
    "    return ' '.join(word.replace(\"_\",\" \")\n",
    "                    for word in final_text.split() if \n",
    "                    is_not_user(word) and\n",
    "                    is_not_stopword(word)).strip() # filtra usuários, stopwords, caracteres especiais e \"_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, um exemplo de alguns dos tweets da base de dados de treinamento e a categoria que foi manualmente dada a eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@jamiltdavis @vicious696 i say the cutoff shou...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@rgt_85 @obe1plays when @rgt_85 tweets at you....</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@one_gamergal6 @xboxstockalerts if you guys st...</td>\n",
       "      <td>Pouco Relevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mbeasleysburner @wario64 they are literally l...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first couple followers to give us a private  m...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento        Categoria  \\\n",
       "0  @jamiltdavis @vicious696 i say the cutoff shou...      Irrelevante   \n",
       "1  @rgt_85 @obe1plays when @rgt_85 tweets at you....      Irrelevante   \n",
       "2  @one_gamergal6 @xboxstockalerts if you guys st...  Pouco Relevante   \n",
       "3  @mbeasleysburner @wario64 they are literally l...      Irrelevante   \n",
       "4  first couple followers to give us a private  m...      Irrelevante   \n",
       "\n",
       "  Unnamed: 2  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = {cat: dict() for cat in train.Categoria.cat.categories}\n",
    "words = set()\n",
    "\n",
    "for i, tweet_data in train.iterrows(): # itera pelas linhas do dataframe\n",
    "    tweet = tweet_data.Treinamento # separa a coluna do tweet\n",
    "    \n",
    "    for word in clean_up(tweet).split(): # faz limpezas no texto\n",
    "        words.add(word)\n",
    "        cat_dict = words_count[tweet_data.Categoria]\n",
    "        cat_dict[word] = cat_dict.get(word, 0)+1 # garante que a palavra existe no dicionario.\n",
    "                                                 # caso exista o count é incrementado,\n",
    "                                                 # caso contrário a palavra é adicionada com count=1.\n",
    "        \n",
    "M = words_count['Muito Relevante']\n",
    "R = words_count['Relevante']\n",
    "P = words_count['Pouco Relevante']\n",
    "I = words_count['Irrelevante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(words)         # total de palavras no banco de dados\n",
    "totalM = (sum(M.values())) # total de palavras na categoria Muito Relevante\n",
    "totalR = (sum(R.values())) # total de palavras na categoria Relevante\n",
    "totalP = (sum(P.values())) # total de palavras na categoria Pouco Relevante\n",
    "totalI = (sum(I.values())) # total de palavras na categoria Irrelevante\n",
    "p_cats = train.Categoria.value_counts()/len(train) #probabilidade de um tweet ser cada categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar o classificador, foram separadas as palavras em cada categoria, para verificar qual a frequência de uso delas. Com essa lista de frequência, cada palavra teve atribuida a ela um valor de relevância, e assim foi comparada à base de dados de teste para concluir se os tweets analizados eram ou não relevantes com base na frequência de certas palavras em cada lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [] # lista de classificações, mesma ordem de test\n",
    "\n",
    "for i, tweet_data in test.iterrows():  # itera pelas linhas do dataframe\n",
    "    # valores inicias para a probabilidade do tweet ser determinada relevancia, começa em probabilidade da categoria para\n",
    "    # sera multiplicado pela probabilidade de cada palavra ser cada categoria.\n",
    "    i = p_cats[\"Irrelevante\"]\n",
    "    p = p_cats[\"Pouco Relevante\"]\n",
    "    r = p_cats[\"Relevante\"]\n",
    "    m = p_cats[\"Muito Relevante\"]\n",
    "    tweet = tweet_data.Teste # separa a coluna do tweet\n",
    "    \n",
    "    # faz limpezas no texto\n",
    "    for word in clean_up(tweet).split(): \n",
    "        \n",
    "        # calcula as probabilidades de cada relevancia fazendo suavizavao de laplace\n",
    "        r *= (R.get(word, 0) + 1) / (totalR + total) \n",
    "        p *= (P.get(word, 0) + 1) / (totalP + total) \n",
    "        i *= (I.get(word, 0) + 1) / (totalI + total) \n",
    "        m *= (M.get(word, 0) + 1) / (totalM + total)\n",
    "        \n",
    "    result = {\"Muito Relevante\": m,\"Relevante\": r,\"Pouco Relevante\": p,\"Irrelevante\": i}\n",
    "    # dicionário para comparar dentro do MAX abaixo\n",
    "    \n",
    "    l.append(max(result, key = result.get)) # compara os valores de r, p, i, e adiciona à lista L \n",
    "\n",
    "test.Categoria = pd.Categorical(values=l,categories=[\"Muito Relevante\",\"Relevante\", \n",
    "                                                     \"Pouco Relevante\", \"Irrelevante\"],ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.gabas = test.gabas.astype(\"category\")\n",
    "test.gabas.cat.categories = test.Categoria.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Acerto\"] = [(\"Acertou\" if (row.gabas==row.Categoria)  else \"Errou\") for i,row in test.iterrows()]\n",
    "test.Acerto = test.Acerto.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, o índice de acertos e erros do classificador com base em um gabarito manualmente gerado.\n",
    "\n",
    "Também foram feitas tabelas que mostram as frequências absolutas e relativas que indicam os acertos em relação ao gabarito, para que fosse possível ver onde houvesse maior dificuldade de discernimento do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acerto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acertou</th>\n",
       "      <td>65.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Errou</th>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Acerto\n",
       "Acertou    65.6\n",
       "Errou      34.4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test.Acerto.value_counts(normalize=True)*100).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gabas</th>\n",
       "      <th>Muito Relevante</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Pouco Relevante</th>\n",
       "      <th>Irrelevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Muito Relevante</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pouco Relevante</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gabas            Muito Relevante  Relevante  Pouco Relevante  Irrelevante\n",
       "Categoria                                                                \n",
       "Muito Relevante                3          0                0            8\n",
       "Relevante                      8         19                3           36\n",
       "Pouco Relevante                0          0               27            5\n",
       "Irrelevante                    3         17                6          115"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Categoria,test.gabas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gabas</th>\n",
       "      <th>Muito Relevante</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Pouco Relevante</th>\n",
       "      <th>Irrelevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Muito Relevante</th>\n",
       "      <td>27.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>12.12</td>\n",
       "      <td>28.79</td>\n",
       "      <td>4.55</td>\n",
       "      <td>54.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pouco Relevante</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.38</td>\n",
       "      <td>15.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>2.13</td>\n",
       "      <td>12.06</td>\n",
       "      <td>4.26</td>\n",
       "      <td>81.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "gabas            Muito Relevante  Relevante  Pouco Relevante  Irrelevante\n",
       "Categoria                                                                \n",
       "Muito Relevante            27.27       0.00             0.00        72.73\n",
       "Relevante                  12.12      28.79             4.55        54.55\n",
       "Pouco Relevante             0.00       0.00            84.38        15.62\n",
       "Irrelevante                 2.13      12.06             4.26        81.56"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Categoria,test.gabas,normalize=\"index\").round(4)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras da categoria Muito Relevante : 592\n",
      "Quantidade de palavras da categoria Relevante : 1870\n",
      "Quantidade de palavras da categoria Pouco Relevante : 1827\n",
      "Quantidade de palavras da categoria Irrelevante : 5328\n"
     ]
    }
   ],
   "source": [
    "pal = [totalM, totalR, totalP, totalI]\n",
    "cats = [\"Muito Relevante\", \"Relevante\", \"Pouco Relevante\", \"Irrelevante\"]\n",
    "\n",
    "for i in range (0, len(pal)):\n",
    "    print(\"Quantidade de palavras da categoria\", cats[i], \":\", pal[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, as frequências de cada categoria de relevância em cada um dos datasets. Primeiro, a base de treinamento, e depois a de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irrelevante        312\n",
       "Relevante           88\n",
       "Pouco Relevante     74\n",
       "Muito Relevante     26\n",
       "Name: Categoria, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Categoria.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irrelevante        164\n",
       "Pouco Relevante     36\n",
       "Relevante           36\n",
       "Muito Relevante     14\n",
       "Name: gabas, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.gabas.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conclusão\n",
    "\n",
    "O Classificador Naive-Bayes criado com o dataset de treinamento obteve um acerto de 65.6%. É possível concluir que o classificador teve resultados razoáveis e na média do esperado para um classificador simples. Ele é considerado simples por não levar em conta coisas como duplas-negações, sarcasmo, e outras nuances linguísticas.\n",
    "\n",
    "A fim de economizar tempo da equipe de marketing do cliente, pode-se afirmar que o classificador cumpriu parcialmente com seus objetivos, porque mesmo tendo dificuldade em discernir entre as categorias muito relevante e relevante, ele tem uma boa precisão quanto aos tweets irrelevantes e pouco relevantes. Sem estes, a maioria restante são de tweets com algum grau de relevância, e estes são fundamentais para a intervenção da área de marketing.\n",
    "\n",
    "O classificador ainda não está em um ponto no qual se possa excluir totalmente a análise manual dos tweets uma vez que 34.4% dos tweets ainda são classificados incorretamente, que são em sua maioria tweets muito relevantes ou relevantes. Isto pode ter sido causado por diferenças de interpretação na classificação manual dos tweets, mas também é afetado pelo não-reconhecimento de coisas como o sarcasmo que já foram citadas. Como plano de melhoria e motivo para continuação do investimento no projeto, seria interessante expandir o dataset em análise com a classificação manual feita por pessoas da área de marketing, melhorando a confiabilidade nos dados do dataset de treinamento. Outra solução que possa ser mais factível de realizar a curto prazo seria procurar adicionar à base de treinamento tweets para melhor treinar o classificador, de maneira que haja uma proporção mais igual entre a quantidade de tweets de cada categoria. Outra possível melhoria seria implementar detecção de ironia, para isso poderíamos usar esta [pesquisa](https://aclanthology.org/S18-1005/) como referência.\n",
    "\n",
    "Seria interessante usar um classificador de Naive-Bayes mais avançado para identificar o interesse de alguém em comportamentos ou atitudes preocupantes, como forma de segurança pública. Por exemplo, [essa reportagem](https://www.nytimes.com/2018/09/06/us/social-media-monitoring-school-shootings.html) indica que seria possível identificar ameaças públicas por meio do monitoramento das redes sociais. Por mais que isso seja invasivo e pouco custo-efetivo, é uma aplicação possível do classificador. \n",
    "\n",
    "Ao mesmo tempo, outra aplicação seria para medir a opinião popular a respeito de uma comunidade ou um termo que a diz respeito, parecido com como se faz no Facebook. Digitar algumas palavras específicas em um comentário (especialmente relacionadas a etnia, sexualidade, gênero e nacionalidade) pode te causar uma penalidade como uma proibição de interagir com e criar novos posts por um período de tempo, porque o algoritmo do Facebook identificou que são palavras geralmente usadas ofensivamente, e por isso passa a punir as pessoas que as usam. Este é um exemplo de algoritmo que, assim como o desenvolvido neste projeto, não é capaz de reconhecer sarcasmo e humor, e acaba punindo pessoas que não ofenderam ninguém com uma palavra que, por um motivo, foi parar na lista de termos ofensivos. Isto revela uma insegurança grande sobre a classificação: é possível gerar uma falsa perspectiva sobre o objeto estudado com base no dataset obtido.\n",
    "\n",
    "Sobre a necessidade de investimento adicional no dataset de treinamento, não é possível criar um novo dataset automaticamente através do próprio classificador já existente pois isso propagaria os erros feitos pelo classificador, reduzindo sua exatidão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(filename)\n",
    "df2 = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "df1 = df1.drop(\"Unnamed: 2\",axis=1)\n",
    "df2 = df2.drop(\"Categoria\",axis=1)\n",
    "df1 = df1.rename(columns={\"Treinamento\":\"Tweet\"})\n",
    "df2 = df2.rename(columns={\"Teste\":\"Tweet\",\"gabas\":\"Categoria\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Muito Relevante', 'Relevante', 'Pouco Relevante', 'Irrelevante'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.concat([df1,df2],ignore_index=True)\n",
    "tweets.Tweet = tweets.Tweet.apply(clean_up)\n",
    "tweets.Categoria = tweets.Categoria.astype('category')\n",
    "tweets.Categoria.cat.categories = [\"Muito Relevante\",\"Relevante\", \"Pouco Relevante\", \"Irrelevante\"]\n",
    "\n",
    "tweets.Categoria.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(df):\n",
    "    words_count = {cat: dict() for cat in df.Categoria.cat.categories}\n",
    "    words = set()\n",
    "    for i, tweet_data in df.iterrows(): # itera pelas linhas do dataframe\n",
    "        tweet = tweet_data.Tweet # separa a coluna do tweet\n",
    "\n",
    "        for word in tweet.split(): # faz limpezas no texto\n",
    "            words.add(word)\n",
    "            cat_dict = words_count[tweet_data.Categoria]\n",
    "            cat_dict[word] = cat_dict.get(word, 0)+1 # garante que a palavra existe no dicionario. caso exista o count é incrementado, caso contrário a palavra é adicionada com count=1\n",
    "    return words, words_count, df.Categoria.value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(words,words_count,p_cats,df):\n",
    "\n",
    "    M = words_count['Muito Relevante']\n",
    "    R = words_count['Relevante']\n",
    "    P = words_count['Pouco Relevante']\n",
    "    I = words_count['Irrelevante']\n",
    "\n",
    "    total = len(words)         # total de palavras no banco de dados\n",
    "    totalM = (sum(M.values())) # total de palavras na categoria Muito Relevante\n",
    "    totalR = (sum(R.values())) # total de palavras na categoria Relevante\n",
    "    totalP = (sum(P.values())) # total de palavras na categoria Pouco Relevante\n",
    "    totalI = (sum(I.values())) # total de palavras na categoria Irrelevante\n",
    "\n",
    "    l = [] # lista de classificações, mesma ordem de test\n",
    "    \n",
    "    for i, tweet_data in df.iterrows():  # itera pelas linhas do dataframe\n",
    "        # valores inicias para a probabilidade do tweet ser determinada relevancia, começa em probabilidade da categoria para\n",
    "        # sera multiplicado pela probabilidade de cada palavra ser cada categoria.\n",
    "        i = p_cats[\"Irrelevante\"]\n",
    "        p = p_cats[\"Pouco Relevante\"]\n",
    "        r = p_cats[\"Relevante\"]\n",
    "        m = p_cats[\"Muito Relevante\"]\n",
    "        tweet = tweet_data.Tweet # separa a coluna do tweets\n",
    "\n",
    "        # faz limpezas no texto\n",
    "        for word in tweet.split(): \n",
    "\n",
    "            # calcula as probabilidades de cada relevancia fazendo suavizavao de laplace\n",
    "            r *= (R.get(word, 0) + 1) / (totalR + total) \n",
    "            p *= (P.get(word, 0) + 1) / (totalP + total) \n",
    "            i *= (I.get(word, 0) + 1) / (totalI + total) \n",
    "            m *= (M.get(word, 0) + 1) / (totalM + total)\n",
    "\n",
    "        result = {\"Muito Relevante\": m,\"Relevante\": r,\"Pouco Relevante\": p,\"Irrelevante\": i} # dicionário para comparar dentro do MAX abaixo\n",
    "\n",
    "        l.append(max(result, key = result.get)) # compara os valores de r, p, i, e adiciona à lista L \n",
    "\n",
    "    df[\"Classificação\"] = pd.Categorical(values=l,categories=[\"Muito Relevante\",\"Relevante\", \"Pouco Relevante\", \"Irrelevante\"],ordered=True)\n",
    "  \n",
    "    df[\"Acerto\"] = [\"Acertou\" if (row[\"Classificação\"]==row.Categoria) else \"Errou\" for i,row in df.iterrows()]\n",
    "    \n",
    "    df.Acerto = df.Acerto.astype('category')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sample() got an unexpected keyword argument 'ignore_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c32154f7d99a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mrandom_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseeds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Separa o df em train e test, com teste de 1/3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sample() got an unexpected keyword argument 'ignore_index'"
     ]
    }
   ],
   "source": [
    "lista_acertos = list()\n",
    "acertos_max = 0\n",
    "seeds = [(11*i+669+i**2) for i in range(100)] # para manter consistência entre execuções\n",
    "\n",
    "for i in range(100):\n",
    "    random_tweets = tweets.sample(frac=1, random_state=seeds[i], ignore_index=True)\n",
    "    # Separa o df em train e test, com teste de 1/3\n",
    "    \n",
    "    train2, test2 =(random_tweets.iloc[:500], random_tweets.iloc[500:])\n",
    "    result = test_classifier(*train_classifier(train2), test2.copy())\n",
    "    lista_acertos.append(result.Acerto.value_counts(normalize=True).Acertou*100)\n",
    "    acertos_max = max(acertos_max,lista_acertos[-1])\n",
    "    if acertos_max == lista_acertos[-1]:\n",
    "        max_acertos_test = result\n",
    "\n",
    "tabela_acertos = pd.DataFrame({\"Acertos\":lista_acertos})\n",
    "tabela_acertos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Histograma de Acertos em diferentes divisões de Teste e Treinamento\")\n",
    "plt.xlabel(\"Acertos (%)\")\n",
    "tabela_acertos.Acertos.hist(bins=15,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(max_acertos_test[\"Classificação\"],max_acertos_test.Categoria,normalize=\"index\").round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(tabela_acertos, vert = False, meanline = True, showcaps = True, showbox = True, showfliers = True,\n",
    "            showmeans = True, notch = True, manage_ticks = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## checklist itens extra\n",
    "\n",
    "- [x] Espaçamento entre emojis\n",
    "- [x] 4 categorias (obrigatorio)\n",
    "- [x] Explicar porque não pode usar o classificador para gerar mais dados de treinamento\n",
    "- [x] Fazer o item 6\n",
    "- [x] Propor outro cenario para naive-bayes\n",
    "- [x] Sugerir melhoria com pesquisa\n",
    "#### Limpezas e transformacoes:\n",
    "    - [x] Stopwords\n",
    "    - [x] Nomes de usuario\n",
    "    - [x] Limpeza de urls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)\n",
    "\n",
    "----\n",
    "## Referencias:\n",
    "* https://mathiasbynens.be/demo/url-regex\n",
    "* https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.htmlhttps://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
